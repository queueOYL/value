# queueOYL_value(编辑中)

在这里我们将用tensorflow调用keras来完成模型的搭建，用mnist模型训练并且验证

keras官网：keras.io

(主代码所在文件名为 Dense.py)

1. mnist数据的导入与处理，不过多阐述
      (minst：包含6w张数字图片，图片规格为28*28，映射到个位数上)
      
2. 开始构建神经网络的框架(keras.models.Sequential)：
      a.  因为数据集为图形，我们可以理解为矩阵(28*28)，处理时将矩阵中每个值映射到[0,1]上
          
      b.  在选择网络层api时，需要注意输入层的数据格式，用input_shape(28,28,1)传入矩阵

      c. 网络层的选择相对自由，注意卷积层 与 全连接层之间，数据需要处理
         下面介绍几种常用层
         
      d.  Conv3D,Conv2D,Conv1D: 不同维度的卷积层，图像上，用二维卷积层Conv2D较多
      
      e.  MaxPooling1D,MaxPooling2D,MaxPooling3D: 不同维度的池化层，
      
      f.  Flatten: 将矩阵降维为‘向量’，(将多维数据处理为一维)
          该方法还常用在卷积层到Dense层，总之经常用在Dense层之前
      
      g.  Dense: 全连接层，最常用的层，处理数据只能为一维，
          与其他神经元连接方法为两两间均有连接，因此多层Dense涉及到的权重变量多
          使用时注意是否需要添加激活函数，Dense默认不添加激活函数
      
      h.  Dropout: 设置一个概率P，让中间部分神经元已P的概率失活，能降低神经网络过拟合的风险
      
      i.  分类问题最后一层通常采用全连接层，激活函数也通常设置为 softmax
          神经元对应目标结果的标签数，mnist中显然是 0—9 共10个
      
3. 配置模型的训练方法(compile):
      a.  优化器：optimizer
      b.  损失函数：loss
      c.  评估训练效果的度量函数：metrics
      三者在keras中都有成型的模块，可直接调用，也可以自定义
            optimizer模块：SGD，Adam ...
            
            losses模块：mean_squared_error , mean_absolute_error , categorical_crossentropy ...
            
            metrics模块：accuracy ... 更多请访问官网：https://keras.io/api/metrics/
            
4.训练模型并且检验：
      mnist的数据量并不大，建议直接采用fit，方便快捷
      
      fit参数中，比较重要的如下
      x,y : 训练集样本和标签
      batch_size：将样本划分为的个数
                  例如batch_size为60，mnist有60000个数据，那么划分后将产生60个1000的小样本
      epochs：训练轮数
      validation_data：指定测试集
      validation_split：设置一个0—1的比例，表示从训练集中划分出多少作为测试集合，与validation_data二选一使用
      
5.训练模型的导出：
      keras自带导出方法
      使用命令 xxx.save('yyy.h5')  例如：model.save('DenseModel.h5')
      xxx为模型的名称，yyy为导出的模型文件名
      导出后，文件夹目录下会出现 h5格式的目标文件 
      该文件包含以下内容：
            模型结构，模型权重，配置的训练方法，优化器状态
   
6.训练模型的加载：
      使用keras.models.load_model加载模型的文件
      以 5 中举例的导出的模型文件为例，别处加载模型时： model = tf.keras.models.load_model('DenseModel.h5')
      注意，可能因为tensorflow版本问题报错
 
7.应用自己训练的神经网络识别互联网上的图片
      我们从网络上下载数字图片后置于 h5 文件同一目录下(保存于其他位置需要标明路径)
      (我将寻找到的四张图片保存在了pic文件夹中，可供测试)
      
      使用cv2库中imread读入图片，例如 ： img = cv.imread("5.jpg")
      
      图片灰度化，调整大小为28*28后，
      使用predict()函数将图片丢入神经网络模型，
      
      将返回值保存输出值，其返回是一个 长度为 10 的向量(对应神经网络最后一层神经元数量)
      该向量储存的是该图片归为哪一类的概率，使用numpy库将其中最大值所在项输出，即为该神经网络模型预测值
      
      形式如下
      [[1.4133823e-05 5.3018945e-09 1.0657323e-08 1.5046079e-07 3.0478643e-07
       9.9638915e-01 3.2289429e-03 1.7946634e-10 3.6726068e-04 1.0253863e-07]]
       
      5
      
      这个5就是预测值，
      注意，对于一些模糊的图片，预测值未必准确，但是通过概率向量中的数值我们也可以辅助判断
      例如比较 概率最高的类别 和 概率次高的类别 间的概率差，小于一定常数，即将此次分类结果定义为模糊的
      或者输出多个可能值



 可以使用print(model.summary())打印结构
 例如：
 
 Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten_1 (Flatten)         (None, 784)               0         
                                                                 
 dense_2 (Dense)             (None, 128)               100480    
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 dense_3 (Dense)             (None, 64)                8256      
                                                                 
 dense_4 (Dense)             (None, 10)                650       
                                                                 
=================================================================
Total params: 109,386
Trainable params: 109,386
Non-trainable params: 0
_________________________________________________________________
None

